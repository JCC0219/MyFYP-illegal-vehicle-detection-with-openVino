{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e68c62-e92c-47a5-b950-6b430156c618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import datetime\n",
    "from IPython import display\n",
    "from openvino.runtime import Core\n",
    "sys.path.append(\"../utils\")\n",
    "import notebook_utils as utils\n",
    "import easyocr\n",
    "reader = easyocr.Reader(['en'], gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd3f430-c2ea-460e-acbd-b1ef4210c143",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "converted_model_path = f\"model/vehicle-license-plate-detection-barrier-0123/FP32/vehicle-license-plate-detection-barrier-0123.xml\"\n",
    "\n",
    "classes = ['','car','plate']\n",
    "# Initialize OpenVINO Runtime.\n",
    "ie_core = Core()\n",
    "# Read the network and corresponding weights from a file.\n",
    "model = ie_core.read_model(model=converted_model_path)\n",
    "# Compile the model for CPU (you can choose manually CPU, GPU, MYRIAD etc.)\n",
    "# or let the engine choose the best available device (AUTO).\n",
    "compiled_model = ie_core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "# Get the input and output nodes.\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layer = compiled_model.output(0)\n",
    "\n",
    "# Get the input size.\n",
    "#height, width = list(input_layer.shape)[1:3]\n",
    "height, width=256,256\n",
    "\n",
    "plate_list= []\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "today_date = now.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c18a6d3f-708c-4719-969c-95ae15080a57",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-56f088c26b6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Colors for the classes above (Rainbow Color Map).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m colors = cv2.applyColorMap(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0msrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcolormap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLORMAP_RAINBOW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m ).squeeze()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# Colors for the classes above (Rainbow Color Map).\n",
    "colors = cv2.applyColorMap(\n",
    "    src=np.arange(0, 255, 255 / len(classes), dtype=np.float32).astype(np.uint8),\n",
    "    colormap=cv2.COLORMAP_RAINBOW,\n",
    ").squeeze()\n",
    "\n",
    "def draw_boxes(frame, boxes):\n",
    "    for label, score, x_min, y_min, x_max, y_max in boxes:\n",
    "        # Choose color for the label.\n",
    "        color = tuple(map(int, colors[label]))\n",
    "        # Draw a box.\n",
    "        x2 = x_min + x_max\n",
    "        y2 = y_min + y_max\n",
    "        cv2.rectangle(img=frame, pt1=(x_min,y_min), pt2=(x_max, y_max), color=color, thickness=3)\n",
    "        \n",
    "        # Draw a label name inside the box.\n",
    "        cv2.putText(\n",
    "            img=frame,\n",
    "            text=f\"{classes[label]} {score:.2f}\",\n",
    "            org=(x_min + 10, y_min + 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "            fontScale=frame.shape[1] / 1000,\n",
    "            color=color,\n",
    "            thickness=1,\n",
    "            lineType=cv2.LINE_AA,\n",
    "        ) \n",
    "\n",
    "    return frame\n",
    "\n",
    "#function to return most length in a list, and then only choose for most frequent\n",
    "def most_frequent_longest_string(str_list):\n",
    "    # Initialize a dictionary to store the frequency of each string\n",
    "    freq_dict = {}\n",
    "    # Loop through each string in the list\n",
    "    for string in str_list:\n",
    "        # If the string is already in the frequency dictionary, increment its count\n",
    "        if string in freq_dict:\n",
    "            freq_dict[string] += 1\n",
    "        # Otherwise, add it to the frequency dictionary with a count of 1\n",
    "        else:\n",
    "            freq_dict[string] = 1\n",
    "\n",
    "    # If the frequency dictionary is empty, return None\n",
    "    if not freq_dict:\n",
    "        return None\n",
    "\n",
    "    # Initialize variables to store the longest and most frequent strings\n",
    "    longest_string = \"\"\n",
    "    max_frequency = 0\n",
    "    max_length = 0\n",
    "    frequent_longest_strings = []\n",
    "    # Loop through each string in the frequency dictionary\n",
    "    for string, frequency in freq_dict.items():\n",
    "        # If the current string is longer than the current longest string, update the longest string and max length\n",
    "        if len(string) > len(longest_string):\n",
    "            longest_string = string\n",
    "            max_length = len(longest_string)\n",
    "            max_frequency = frequency\n",
    "            frequent_longest_strings = [longest_string]\n",
    "        # If the current string has the same length as the current longest string and a higher frequency, update the max frequency and add the string to the list of frequent longest strings\n",
    "        elif len(string) == len(longest_string) and frequency == max_frequency:\n",
    "            frequent_longest_strings.append(string)\n",
    "        # If the current string has the same length as the current longest string and a higher frequency, update the max frequency and reset the list of frequent longest strings with the current string\n",
    "        elif len(string) == len(longest_string) and frequency > max_frequency:\n",
    "            max_frequency = frequency\n",
    "            frequent_longest_strings = [string]\n",
    "\n",
    "    # Return the list of frequent longest strings\n",
    "    return frequent_longest_strings\n",
    "\n",
    "\n",
    "def retrieve_coordinate(bgr_image, resized_image, boxes, threshold=0.3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Use bounding boxes from detection model to find the absolute car position [1] label position [2]\n",
    "    \n",
    "    :param: bgr_image: raw image\n",
    "    :param: resized_image: resized image\n",
    "    :param: boxes: detection model returns rectangle position\n",
    "    :param: threshold: confidence threshold\n",
    "    :returns: car_position: car's absolute position\n",
    "    \"\"\"\n",
    "    # Fetch image shapes to calculate ratio\n",
    "    (real_y, real_x), (resized_y, resized_x) = bgr_image.shape[:2], resized_image.shape[:2]\n",
    "    ratio_x, ratio_y = real_x / resized_x, real_y / resized_y\n",
    "    \n",
    "    # Find the boxes ratio\n",
    "    boxes = boxes[:, 1:]\n",
    "\n",
    "    # Store the vehicle's position\n",
    "    position = []\n",
    "    # Iterate through non-zero boxes\n",
    "    for box in boxes:\n",
    "        # Pick confidence factor from last place in array\n",
    "        conf = box[1]\n",
    "        if conf > threshold:\n",
    "            # Convert float to int and multiply corner position of each box by x and y ratio\n",
    "            # In case that bounding box is found at the top of the image, \n",
    "            # we position upper box bar little bit lower to make it visible on image \n",
    "            (x_min, y_min, x_max, y_max) = [\n",
    "                int(max(corner_position * ratio_y * resized_y, 10)) if idx % 2 \n",
    "                else int(corner_position * ratio_x * resized_x)\n",
    "                for idx, corner_position in enumerate(box[2:])\n",
    "            ]\n",
    "            position.append([int(box[0]),conf,x_min, y_min, x_max, y_max])         \n",
    "    return position\n",
    "\n",
    "def save_result_to_txt(plate_no):\n",
    "    if not plate_no:\n",
    "        return\n",
    "    else:\n",
    "        now = datetime.datetime.now()\n",
    "        date_string = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        with open(f'{today_date} report.txt', \"a\") as f:\n",
    "            f.write(plate_no + \"\\tTime: \" + date_string + \"\\n\")\n",
    "\n",
    "def save_plate_image(img, plate_pos):\n",
    "    # Select a vehicle to recognize.\n",
    "    pos = plate_pos[0]\n",
    "    # Crop the image with [y_min:y_max, x_min:x_max].\n",
    "    test_car = img[pos[3]:pos[5], pos[2]:pos[4]]\n",
    "    #test_car = img[pos[1]:pos[3], pos[0]:pos[2]]\n",
    "\n",
    "    # Resize the image to input_size.\n",
    "    if test_car.size == 0:\n",
    "        return\n",
    "    resized_image_re = cv2.resize(test_car, (pos[4]-pos[2], pos[5]-pos[3]))\n",
    "    #plt_show(cv2.cvtColor(resized_image_re, cv2.COLOR_BGR2RGB))\n",
    "    cv2.imwrite(\"temp_plate.jpg\", resized_image_re)\n",
    "    result0= reader.readtext(\"temp_plate.jpg\")\n",
    "    \n",
    "    if not result0:   #return nothing while not detect the words from image\n",
    "        plate_list.append('')\n",
    "        return\n",
    "    else:\n",
    "        #save all carplate to plate_list, and save to txt file\n",
    "        if(result0[0][2] > 0.8): #check if the word ocr conf >0.6\n",
    "            result = np.array(result0,dtype=object)\n",
    "            # Create an empty list to store the middle numbers\n",
    "            plate_no = []\n",
    "            # Loop through the rows of the array\n",
    "            for index, val in enumerate(result):\n",
    "                if result[index][2] <= 0.9:\n",
    "                    continue\n",
    "                # Get the middle number of each row\n",
    "                middle_number = val[len(val) // 2]\n",
    "                # Append the middle number to the list\n",
    "                plate_no.append(middle_number)\n",
    "            # Convert the list of numbers to a single string\n",
    "            plate_no = \" \".join(str(x) for x in plate_no)\n",
    "            plate_no = plate_no.replace(\" \", \"\")\n",
    "            \n",
    "            #further process the result if only detected plate number length > 3\n",
    "            if len(plate_no) > 3:\n",
    "                plate_list.append(plate_no) # append carplate to plate_list\n",
    "                #save to txt file if only plate_list> 20\n",
    "                if len(plate_list) >30 :\n",
    "                    predicted_number = most_frequent_longest_string(plate_list)\n",
    "                    for plate_number in predicted_number:\n",
    "                        save_result_to_txt(plate_number)\n",
    "                         \n",
    "                    plate_list.clear()\n",
    "            else:\n",
    "                plate_list.append('')\n",
    "                return\n",
    "            \n",
    "def run_object_detection(source=0, flip=False, use_popup=False, skip_first_frames=0):\n",
    "    width, height = 256,256\n",
    "    player = None\n",
    "    try:\n",
    "        # Create a video player to play with target fps.\n",
    "        player = utils.VideoPlayer(\n",
    "            source=source, flip=flip, fps=30, skip_first_frames=skip_first_frames\n",
    "        )\n",
    "        # Start capturing.\n",
    "        player.start()\n",
    "        if use_popup:\n",
    "            title = \"Press ESC to Exit\"\n",
    "            cv2.namedWindow(\n",
    "                winname=title, flags=cv2.WINDOW_GUI_NORMAL | cv2.WINDOW_AUTOSIZE\n",
    "            )\n",
    "\n",
    "        processing_times = collections.deque()\n",
    "        while True:\n",
    "            # Grab the frame.\n",
    "            frame = player.next()\n",
    "            if frame is None:\n",
    "                print(\"Source ended\")\n",
    "                break\n",
    "            # If the frame is larger than full HD, reduce size to improve the performance.\n",
    "            scale = 1440 / max(frame.shape)\n",
    "            if scale < 1:\n",
    "                frame = cv2.resize(\n",
    "                    src=frame,\n",
    "                    dsize=None,\n",
    "                    fx=scale,\n",
    "                    fy=scale,\n",
    "                    interpolation=cv2.INTER_AREA,\n",
    "                )\n",
    "\n",
    "            # Resize the image and change dims to fit neural network input.\n",
    "            input_img = cv2.resize(\n",
    "                src=frame, dsize=(width, height), interpolation=cv2.INTER_AREA\n",
    "            )\n",
    "            resized_image = input_img\n",
    "            \n",
    "            # Create a batch of images (size = 1).\n",
    "            input_img = input_img[np.newaxis, ...]\n",
    "            \n",
    "            # Measure processing time.\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Get the results.\n",
    "            boxes = compiled_model([input_img])[output_layer]\n",
    "            \n",
    "            # process result\n",
    "            # Delete the dim of 0, 1.\n",
    "            boxes = np.squeeze(boxes,(0,1))\n",
    "            \n",
    "            # Remove zero only boxes.\n",
    "            boxes = boxes[~np.all(boxes ==0, axis=1)]\n",
    "            \n",
    "            #seperate label object\n",
    "            if boxes is None:\n",
    "                car_pos = []\n",
    "                plate_pos = []\n",
    "            else:\n",
    "                if len(boxes) == 0:\n",
    "                    car_pos = []\n",
    "                    plate_pos = []\n",
    "                else:\n",
    "                    car_pos = boxes[boxes[:, 1] == 1]\n",
    "                    plate_pos = boxes[boxes[:, 1] == 2]\n",
    "\n",
    "            frame_ori=frame.copy()\n",
    "            car_pos=retrieve_coordinate(frame,resized_image,car_pos,threshold=0.3)   \n",
    "            plate_pos=retrieve_coordinate(frame,resized_image,plate_pos,threshold=0.3)   \n",
    "            \n",
    "            #if both have not empty list\n",
    "            # Draw boxes on a frame.\n",
    "            if(((not car_pos) | (not plate_pos)) == 0):   \n",
    "                frame = draw_boxes(frame=frame, boxes=plate_pos)\n",
    "                frame = draw_boxes(frame=frame, boxes=car_pos)\n",
    "                save_plate_image(frame_ori,plate_pos)\n",
    "            else:\n",
    "                #insert empty string to list every frame\n",
    "                plate_list.append(\"\")\n",
    "            \n",
    "            #clear and save every 15 frame\n",
    "            if len(plate_list) > 30:\n",
    "                predicted_number = most_frequent_longest_string(plate_list)\n",
    "                for plate_number in predicted_number:\n",
    "                    save_result_to_txt(plate_number)\n",
    "                plate_list.clear()\n",
    "                \n",
    "            stop_time = time.time()\n",
    "            \n",
    "            processing_times.append(stop_time - start_time)\n",
    "            # Use processing times from last 200 frames.\n",
    "            if len(processing_times) > 200:\n",
    "                processing_times.popleft()\n",
    "            \n",
    "            _, f_width = frame.shape[:2]\n",
    "            # Mean processing time [ms].\n",
    "            processing_time = np.mean(processing_times) * 1000\n",
    "            fps = 1000 / processing_time\n",
    "            \n",
    "            print('fps',fps)\n",
    "            \n",
    "#             cv2.putText(\n",
    "#                 img=frame,\n",
    "#                 text=f\"Inference time: {processing_time:.1f}ms ({fps:.1f} FPS)\",\n",
    "#                 org=(20, 40),\n",
    "#                 fontFace=cv2.FONT_HERSHEY_COMPLEX,\n",
    "#                 fontScale=f_width / 1000,\n",
    "#                 color=(0, 0, 255),\n",
    "#                 thickness=1,\n",
    "#                 lineType=cv2.LINE_AA,\n",
    "#             )\n",
    "\n",
    "#             #Use this workaround if there is flickering.\n",
    "#             if use_popup:\n",
    "#                 cv2.imshow(winname=title, mat=frame)\n",
    "#                 key = cv2.waitKey(1)\n",
    "#                 # escape = 27\n",
    "#                 if key == 27:\n",
    "#                     break\n",
    "#             else:\n",
    "#                 # Encode numpy array to jpg.\n",
    "#                 _, encoded_img = cv2.imencode(\n",
    "#                     ext=\".jpg\", img=frame, params=[cv2.IMWRITE_JPEG_QUALITY, 100]\n",
    "#                 )\n",
    "#                 # Create an IPython image.\n",
    "#                 i = display.Image(data=encoded_img)\n",
    "#                 # Display the image in this notebook.\n",
    "#                 display.clear_output(wait=True)\n",
    "#                 display.display(i)\n",
    "    # ctrl-c\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Interrupted\")\n",
    "    # any different error\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if player is not None:\n",
    "            # Stop capturing.\n",
    "            player.stop()\n",
    "        if use_popup:\n",
    "            cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449fc08-daa0-43d9-81a5-1d74b818efe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_object_detection(source=\"images/front4.mp4\", flip=False, use_popup=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
